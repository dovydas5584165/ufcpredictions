import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import seaborn as sns
import matplotlib.pyplot as plt

# Load data
try:
    best_xgb = joblib.load('best_xgb_model.pkl')
    scaler = joblib.load('scaler.pkl')
    imputer = joblib.load('imputer.pkl')
    print("Model, scaler, and imputer loaded successfully.")
except (FileNotFoundError, EOFError):
    print("Training the model as no saved files were found.")

    df = pd.read_csv('large_dataset.csv')

    # Drop rows with missing target values
    df = df.dropna(subset=['winner'])

    # Feature engineering: differences between fighters' stats
    df['age_diff'] = df['r_age'] - df['b_age']
    df['height_diff'] = df['r_height'] - df['b_height']
    df['weight_diff'] = df['r_weight'] - df['b_weight']
    df['rev_diff'] = df['r_rev'] - df['b_rev']
    df['sig_str_diff'] = df['r_sig_str_acc'] - df['b_sig_str_acc']
    df['td_def_diff'] = df['r_td_def_total'] - df['b_td_def_total']
    
    # Target encoding (1 = Red, 0 = Blue)
    df['target'] = df['winner'].map({'Red': 1, 'Blue': 0})

    # Define features (Removed 'ctrl_sec_diff')
    features = ['age_diff', 'height_diff', 'weight_diff', 'rev_diff', 'sig_str_diff', 'td_def_diff']
    X = df[features]
    y = df['target']

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # Handle missing values
    imputer = SimpleImputer(strategy='mean')
    X_train = imputer.fit_transform(X_train)
    X_test = imputer.transform(X_test)

    # Balance the dataset with SMOTE
    smote = SMOTE(random_state=42)
    X_train, y_train = smote.fit_resample(X_train, y_train)

    # Feature scaling
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # XGBoost hyperparameter tuning
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.8, 1.0],
        'colsample_bytree': [0.8, 1.0]
    }

    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
    grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
    grid_search.fit(X_train, y_train)

    # Best model
    best_xgb = grid_search.best_estimator_

    # Save the model, scaler, and imputer
    joblib.dump(best_xgb, 'best_xgb_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')
    joblib.dump(imputer, 'imputer.pkl')
    print("Model, scaler, and imputer saved successfully.")

# Stats for Song Yadong (Red) and Henry Cejudo (Blue)
song_yadong_stats = {
    'r_age': 35, 'r_height': 5.8, 'r_weight': 66, 'r_rev': 10, 'r_sig_str_acc': 48, 'r_td_def_total': 15
}

henry_cejudo_stats = {
    'b_age': 35, 'b_height': 5.4, 'b_weight': 61, 'b_rev': 15, 'b_sig_str_acc': 58, 'b_td_def_total': 10
}

# Combine the stats of both fighters
fighter_data = pd.DataFrame([song_yadong_stats | henry_cejudo_stats])

# Calculate feature differences (Removed 'ctrl_sec_diff')
fighter_data['age_diff'] = fighter_data['r_age'] - fighter_data['b_age']
fighter_data['height_diff'] = fighter_data['r_height'] - fighter_data['b_height']
fighter_data['weight_diff'] = fighter_data['r_weight'] - fighter_data['b_weight']
fighter_data['rev_diff'] = fighter_data['r_rev'] - fighter_data['b_rev']
fighter_data['sig_str_diff'] = fighter_data['r_sig_str_acc'] - fighter_data['b_sig_str_acc']
fighter_data['td_def_diff'] = fighter_data['r_td_def_total'] - fighter_data['b_td_def_total']

# Prepare input for prediction
fighter_input = fighter_data[features]
fighter_input = imputer.transform(fighter_input)  # Handle missing values
fighter_input = scaler.transform(fighter_input)  # Scale data

# Predict probabilities (for Red and Blue fighter)
probabilities = best_xgb.predict_proba(fighter_input)

# Output probability of winning
print(f'Probability of Red Fighter (Song Yadong) winning: {probabilities[0][1] * 100:.2f}%')
print(f'Probability of Blue Fighter (Henry Cejudo) winning: {probabilities[0][0] * 100:.2f}%')

# Model Predictions
y_pred = best_xgb.predict(X_test)

# Accuracy Score
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy * 100:.2f}%")

# Get feature importance
feature_importance = best_xgb.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': feature_importance
}).sort_values(by='Importance', ascending=False)

# Print feature importance
print("Feature Contributions:")
print(feature_importance_df)

# Plot feature importance
plt.figure(figsize=(10, 5))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette="viridis")
plt.title("Feature Importance (XGBoost)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.show()
